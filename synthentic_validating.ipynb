{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthentic Validating Text-to-image Model\n",
    "This notebook mimics the validation process when validating an T2I Endpoint\n",
    "The Validator contain 2 main components:\n",
    "1. Prompter: Generate T2I prompt by requested topic\n",
    "2. Rewarder: Calculate the reward of the generated images - prompt pair."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/luan_tt/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from ig_rewarding import Validator\n",
    "import pandas as pd\n",
    "import json\n",
    "from typing import List\n",
    "import numpy as np\n",
    "from transformers import Pipeline\n",
    "from diffusers import StableDiffusionPipeline, StableDiffusionXLPipeline\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from ig_rewarding.utils import instantiate_from_config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Validating Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRY_PER_ENDPOINT = 50\n",
    "N_IMAGE_PER_PROMPT = 4\n",
    "\n",
    "TOPICS = ['animated style', 'robotic style', 'realistic style']\n",
    "ENDPOINTS = {\n",
    "    \"sd\": [\"CompVis/stable-diffusion-v1-4\", \"runwayml/stable-diffusion-v1-5\"],\n",
    "    \"sdxl\": [\"segmind/SSD-1B\", \"stabilityai/stable-diffusion-xl-base-1.0\"],\n",
    "}\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "SAVE_DIR = \"outputs\"\n",
    "config_file = \"ig_rewarding/config/baseline.yaml\"\n",
    "config = yaml.load(open(config_file, \"r\"), Loader=yaml.FullLoader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init the Validator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from /root/.cache/ImageReward/ImageReward.pt\n",
      "checkpoint loaded\n",
      "load checkpoint from /root/.cache/ImageReward/model_large.pth\n",
      "checkpoint loaded\n",
      "Prompt database already exists. Skipping creation.\n"
     ]
    }
   ],
   "source": [
    "validator = Validator(config[\"rewarder\"], config[\"prompter\"], device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Loop for Validating above Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "import json\n",
    "\n",
    "def validate_pipe(validator: Validator, pipe: Pipeline, pipeline_name: str, topics: List[str], n_try: int, n_image_per_prompt: int, save_dir: str = 'images'):\n",
    "    print(f\"START VALIDATE {pipeline_name}\")\n",
    "    raw_pipeline_name = pipeline_name\n",
    "    pipeline_name = pipeline_name.replace(\"/\", \"_\")\n",
    "    request_result = []\n",
    "    for i in range(n_try):\n",
    "        request_id = i\n",
    "        prompts = validator.generate_prompt(topics)\n",
    "        \n",
    "        for j in range(n_image_per_prompt):\n",
    "            outputs = pipe(prompts, num_images_per_prompt=1)\n",
    "            file_names = [f\"{pipeline_name}_{i}_{j*len(prompts)+t}.webp\" for t in range(len(prompts))]\n",
    "            images = outputs.images\n",
    "            for file_name, topic, prompt in zip(file_names, topics, prompts):\n",
    "                request_result.append({\n",
    "                    \"file_name\": file_name,\n",
    "                    \"topic\": topic,\n",
    "                    \"prompt\": prompt,\n",
    "                    \"request_id\": request_id,\n",
    "                    \"model_type\": raw_pipeline_name,\n",
    "                })\n",
    "            for file_name, image in zip(file_names, images):\n",
    "                image.save(os.path.join(save_dir, file_name))\n",
    "        return request_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  6.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START VALIDATE CompVis/stable-diffusion-v1-4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 11.48it/s]\n",
      "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.42it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.39it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.37it/s]\n",
      "Loading pipeline components...: 100%|██████████| 7/7 [00:02<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START VALIDATE runwayml/stable-diffusion-v1-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 219.75it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 13.96it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.33it/s]\n",
      "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.31it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.28it/s]\n",
      "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START VALIDATE segmind/SSD-1B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 206.34it/s]\n",
      "100%|██████████| 50/50 [00:11<00:00,  4.29it/s]\n",
      "100%|██████████| 50/50 [00:11<00:00,  4.30it/s]\n",
      "100%|██████████| 50/50 [00:11<00:00,  4.29it/s]\n",
      "100%|██████████| 50/50 [00:11<00:00,  4.27it/s]\n",
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START VALIDATE stabilityai/stable-diffusion-xl-base-1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 225.26it/s]\n",
      "100%|██████████| 50/50 [00:18<00:00,  2.73it/s]\n",
      "100%|██████████| 50/50 [00:18<00:00,  2.72it/s]\n",
      "100%|██████████| 50/50 [00:18<00:00,  2.71it/s]\n",
      "100%|██████████| 50/50 [00:18<00:00,  2.70it/s]\n",
      "100%|██████████| 4/4 [02:57<00:00, 54.43s/it]"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "total_endpoints = 0\n",
    "for sd_type, endpoints in ENDPOINTS.items():\n",
    "    total_endpoints += len(endpoints)\n",
    "progress_bar = tqdm.tqdm(total=total_endpoints)\n",
    "metadata = []\n",
    "shutil.rmtree(SAVE_DIR, ignore_errors=True)\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "for sd_type, endpoints in ENDPOINTS.items():\n",
    "    for endpoint in endpoints:\n",
    "        if sd_type == \"sd\":\n",
    "            pipe = StableDiffusionPipeline.from_pretrained(endpoint, torch_dtype=torch.float16)\n",
    "        else:\n",
    "            pipe = StableDiffusionXLPipeline.from_pretrained(endpoint, torch_dtype=torch.float16, use_safetensors=True, variant=\"fp16\")\n",
    "        pipe = pipe.to(DEVICE)\n",
    "        sub_metadata = validate_pipe(validator, pipe, endpoint, TOPICS, N_TRY_PER_ENDPOINT, N_IMAGE_PER_PROMPT, save_dir=SAVE_DIR)\n",
    "        metadata.extend(sub_metadata)\n",
    "        with open(os.path.join(SAVE_DIR, \"metadata.jsonl\"), \"w\") as f:\n",
    "            for item in metadata:\n",
    "                f.write(json.dumps(item) + \"\\n\")\n",
    "        progress_bar.update(1)\n",
    "        del pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resolving data files: 100%|██████████| 49/49 [00:00<00:00, 195176.54it/s]\n",
      "Downloading data files: 100%|██████████| 49/49 [00:00<00:00, 71040.75it/s]\n",
      "Downloading data files: 0it [00:00, ?it/s]\n",
      "Extracting data files: 0it [00:00, ?it/s]\n",
      "Generating train split: 48 examples [00:00, 3323.98 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"imagefolder\", data_dir=\"/root/edward/stablediffusion/ig-rewarding/outputs\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'topic', 'prompt', 'request_id', 'model_type'],\n",
       "    num_rows: 48\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 48/48 [00:00<00:00, 2616.43 examples/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 112.94ba/s]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:01<00:00,  1.26s/it]\n",
      "Deleting unused files from dataset repository: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s]\n"
     ]
    }
   ],
   "source": [
    "ds.push_to_hub(\"toilaluan/ig_rewarding_db\", token=\"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\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "luan_tt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
